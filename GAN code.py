# -*- coding: utf-8 -*-
"""Copy of DL-Generative-Model-Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nPjVOZh2WuMSfeiteli53yWQwnX2DgLk
"""

# this code is based on [ref], which is released under the MIT licesne
# make sure you reference any code you have studied as above here

# imports
import math
import numpy as np
import time
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
import torchvision
import matplotlib.pyplot as plt
import numpy as np

#HYPERPARAMETERS
ngpu = 1#cuda gpu's
nz = 100#noise dim
ngf = 64#g filters
ndf = 64#d filters
epochs = 1000
batch_size=128
nc=3#Number of channels in img, rgb is 3

transforms=transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])

dataset = 'cifar10'#Cifar10 then stl10
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

# optional for Colab use only - Google drive integration - this will allow you to save and resume training, and may speed up redownloading the dataset
from google.colab import drive
drive.mount('/content/drive')

# you may use cifar10 or stl10 datasets
if dataset == 'cifar10':
    dataloader = torch.utils.data.DataLoader(
        torchvision.datasets.CIFAR10('drive/My Drive/training/cifar10', train=True, download=True, transform=transforms),
        shuffle=True, batch_size=batch_size, drop_last=True
    )
    class_names = ['airplane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

# stl10 has larger images which are much slower to train on. You should develop your method with CIFAR-10 before experimenting with STL-10
if dataset == 'stl10':
    dataloader = torch.utils.data.DataLoader(
        torchvision.datasets.STL10('drive/My Drive/training/stl10', split='train+unlabeled', download=True, transform=transforms),
        shuffle=True, batch_size=batch_size, drop_last=True)
    class_names = ['airplane', 'bird', 'car', 'cat', 'deer', 'dog', 'horse', 'monkey', 'ship', 'truck'] # these are slightly different to CIFAR-10

"""
**DCGAN**"""

# custom weights initialization called on netG and netD
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        m.weight.data.normal_(0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        m.weight.data.normal_(1.0, 0.02)
        m.bias.data.fill_(0)

class Generator(nn.Module):
    def __init__(self, ngpu):
        super(Generator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),#z
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),#4x4
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),#8x8
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),#16x16
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),#32x#32
            nn.Tanh()#64x64
        )
    def forward(self, input):
        if input.is_cuda and self.ngpu > 1:
            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))
        else:
            output = self.main(input)
            return output

class Discriminator(nn.Module):
    def __init__(self, ngpu):
        super(Discriminator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),#64
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),#32
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),#16
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),#8
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),#4
            nn.Sigmoid()
        )

    def forward(self, input):
        if input.is_cuda and self.ngpu > 1:
            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))
        else:
            output = self.main(input)

        return output.view(-1, 1).squeeze(1)

"""**Main training loop**"""

netG = Generator(ngpu).to(device)
netG.apply(weights_init)#Create generator
netD = Discriminator(ngpu).to(device)
netD.apply(weights_init)#Create discriminator
criterion = nn.BCELoss()
# setup optimizer
optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))
real_label = 1
fake_label = 0


for epoch in range(epochs):
    for i, data in enumerate(dataloader, 0):
        #Update discriminator
        netD.zero_grad()
        real_cpu = data[0].to(device)
        batch_size = real_cpu.size(0)
        label = torch.full((batch_size,), real_label, device=device)
        output = netD(real_cpu)
        errD_real = criterion(output, label.float())
        errD_real.backward()#Backgpropagate
        D_x = output.mean().item()
        # train with fake images
        noise = torch.randn(batch_size, nz, 1, 1, device=device)
        fake = netG(noise)
        label.fill_(fake_label)
        output = netD(fake.detach())
        errD_fake = criterion(output, label.float())
        errD_fake.backward()#Backgpropagate
        D_G_z1 = output.mean().item()
        errD = errD_real + errD_fake
        optimizerD.step()
        #Update generator
        netG.zero_grad()
        label.fill_(real_label) 
        output = netD(fake)
        errG = criterion(output, label.float())
        errG.backward()#Backgpropagate
        D_G_z2 = output.mean().item()
        optimizerG.step()
        #save the output
        if i==300:
            fixed_noise = torch.randn(128, nz, 1, 1, device=device)
            fake = netG(fixed_noise)
            plt.rcParams['figure.dpi'] = 175
            plt.grid(False)
            grid=torchvision.utils.make_grid(fake[:64],normalize=True)
            plt.imshow(torchvision.utils.make_grid(fake[:64],normalize=True).cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)
            plt.show()
            plt.pause(0.0001)
            images_dir = '/content/drive/My Drive/Images'
            torchvision.utils.save_image(grid,images_dir+"/"+str(epoch)+str(i)+"IMAGE.png")


            # now show some interpolations (note you do not have to do linear interpolations as shown here, you can do non-linear or gradient-based interpolation if you wish)

            col_size = int(8)
            z=torch.randn(128, nz, 1, 1, device=device)
            z0 = z[0:col_size].repeat(col_size,1,1,1) # z for top row
            z1 = z[batch_size-col_size:].repeat(col_size,1,1,1) # z for bottom row

            t = torch.linspace(0,1,col_size).unsqueeze(1).repeat(1,col_size).view(64,1,1,1).to(device)

            lerp_z = (1-t)*z0 + t*z1 # linearly interpolate between two points in the latent space
            lerp_g = netG(lerp_z) # sample the model at the resulting interpolated latents

            plt.rcParams['figure.dpi'] = 175
            plt.grid(False)
            #plt.imshow(torchvision.utils.make_grid(lerp_g,normalize=True).cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)
            #plt.show()
            grid=torchvision.utils.make_grid(lerp_g,normalize=True)
            torchvision.utils.save_image(grid,images_dir+"/"+str(epoch)+str(i)+"INTERPOLATE.png")